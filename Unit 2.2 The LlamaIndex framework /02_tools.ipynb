{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaabiin5/Hugging_Face_Formation/blob/main/tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrDCgnvtuKXz"
      },
      "source": [
        "# Tools in LlamaIndex\n",
        "\n",
        "\n",
        "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
        "\n",
        "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
        "\n",
        "## Let's install the dependencies\n",
        "\n",
        "We will install the dependencies for this unit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QcxZyV3cuKX0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface llama-index-tools-google -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToBLuvaluKX3"
      },
      "source": [
        "And, let's log in to Hugging Face to use serverless Inference APIs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ONlSEHFbuKX7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1efe154d5f14b1a9e5826f59f2db0ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2sSVWBjuKX8"
      },
      "source": [
        "## Creating a FunctionTool\n",
        "\n",
        "Let's create a basic `FunctionTool` and call it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "il9iqPdwuKX-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting weather for New York\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ToolOutput(content='The weather in New York is sunny', tool_name='my_weather_tool', raw_input={'args': ('New York',), 'kwargs': {}}, raw_output='The weather in New York is sunny', is_error=False)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"Useful for getting the weather for a given location.\"\"\"\n",
        "    print(f\"Getting weather for {location}\")\n",
        "    return f\"The weather in {location} is sunny\"\n",
        "\n",
        "\n",
        "tool = FunctionTool.from_defaults(\n",
        "    get_weather,\n",
        "    name=\"my_weather_tool\",\n",
        "    description=\"Useful for getting the weather for a given location.\",\n",
        ")\n",
        "tool.call(\"New York\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVx-6CPTuKYB"
      },
      "source": [
        "## Creating a QueryEngineTool\n",
        "\n",
        "Let's now re-use the `QueryEngine` we defined in the [previous unit on tools](/tools.ipynb) and convert it into a `QueryEngineTool`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5EZIUxAzuKYC",
        "outputId": "a955537b-b5bd-4b81-a58b-599a6880c24f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ToolOutput(content=' The introduction and development of artificial intelligence (AI) have had significant effects on various aspects of work and society. It has both positive and negative impacts, depending on the context and application.\\n\\nOn one hand, AI has increased efficiency in many industries, leading to faster processes, cost reductions, and improved decision-making. This can contribute to a better quality of life for people, as goods and services become more accessible and affordable. Additionally, AI has the potential to create new job opportunities by opening up fields like AI development, data analysis, and automation management.\\n\\nOn the other hand, AI may lead to workforce displacement in some sectors, particularly those that are repetitive or routine-based. This can result in job loss for workers who cannot adapt to new skill requirements. Furthermore, it raises ethical concerns about privacy, surveillance, and data security, as well as potential biases in AI systems that could contribute to social inequalities.\\n\\nOverall, the impact of AI on work and society is multifaceted and ever-evolving. It requires continuous research and monitoring to understand its effects fully, address potential challenges, and maximize the benefits for all members of society.', tool_name='some useful name', raw_input={'input': 'Responds about research on the impact of AI on the future of work and society?'}, raw_output=Response(response=' The introduction and development of artificial intelligence (AI) have had significant effects on various aspects of work and society. It has both positive and negative impacts, depending on the context and application.\\n\\nOn one hand, AI has increased efficiency in many industries, leading to faster processes, cost reductions, and improved decision-making. This can contribute to a better quality of life for people, as goods and services become more accessible and affordable. Additionally, AI has the potential to create new job opportunities by opening up fields like AI development, data analysis, and automation management.\\n\\nOn the other hand, AI may lead to workforce displacement in some sectors, particularly those that are repetitive or routine-based. This can result in job loss for workers who cannot adapt to new skill requirements. Furthermore, it raises ethical concerns about privacy, surveillance, and data security, as well as potential biases in AI systems that could contribute to social inequalities.\\n\\nOverall, the impact of AI on work and society is multifaceted and ever-evolving. It requires continuous research and monitoring to understand its effects fully, address potential challenges, and maximize the benefits for all members of society.', source_nodes=[NodeWithScore(node=TextNode(id_='b791fbd0-393d-4cd4-bbf7-f4cceb94a641', embedding=None, metadata={'file_path': '/home/gan/Documents/GIT_COPY/Hugging_Face_Formation/Unit 2.2 The LlamaIndex framework /data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-20', 'last_modified_date': '2025-06-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e6e9b540-201c-4fc2-9c40-2d66c43fa70c', node_type='4', metadata={'file_path': '/home/gan/Documents/GIT_COPY/Hugging_Face_Formation/Unit 2.2 The LlamaIndex framework /data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-20', 'last_modified_date': '2025-06-20'}, hash='fa29696408be890c8b350df10a69f28c8ba7e3aa8a40292b85d2b55ef28715fe')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3740849702943643), NodeWithScore(node=TextNode(id_='748c2f9d-7db1-47c5-91b3-836519b64d52', embedding=None, metadata={'file_path': '/home/gan/Documents/GIT_COPY/Hugging_Face_Formation/Unit 2.2 The LlamaIndex framework /data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-06-20', 'last_modified_date': '2025-06-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='43564548-a228-4654-94cc-49bcd323f5bf', node_type='4', metadata={'file_path': '/home/gan/Documents/GIT_COPY/Hugging_Face_Formation/Unit 2.2 The LlamaIndex framework /data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-06-20', 'last_modified_date': '2025-06-20'}, hash='03ad1f0702c699642c5a8c6f49f3ab7965f757a57bc61d6de2fcec073c7ac836')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An environmental historian or urban planner focused on ecological conservation and sustainability, likely working in local government or a related organization.', mimetype='text/plain', start_char_idx=0, end_char_idx=160, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.372797742886133)], metadata={'b791fbd0-393d-4cd4-bbf7-f4cceb94a641': {'file_path': '/home/gan/Documents/GIT_COPY/Hugging_Face_Formation/Unit 2.2 The LlamaIndex framework /data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-06-20', 'last_modified_date': '2025-06-20'}, '748c2f9d-7db1-47c5-91b3-836519b64d52': {'file_path': '/home/gan/Documents/GIT_COPY/Hugging_Face_Formation/Unit 2.2 The LlamaIndex framework /data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-06-20', 'last_modified_date': '2025-06-20'}}), is_error=False)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import chromadb\n",
        "\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "\n",
        "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
        "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "# llm = HuggingFaceInferenceAPI(model_name=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "llm = Ollama(model=\"openchat:latest\")\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store=vector_store, embed_model=embed_model\n",
        ")\n",
        "query_engine = index.as_query_engine(llm=llm)\n",
        "tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=query_engine,\n",
        "    name=\"some useful name\",\n",
        "    description=\"some useful description\",\n",
        ")\n",
        "await tool.acall(\n",
        "    \"Responds about research on the impact of AI on the future of work and society?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Px3-EMuKYF"
      },
      "source": [
        "## Creating Toolspecs\n",
        "\n",
        "Let's create a `ToolSpec` from the `GmailToolSpec` from the LlamaHub and convert it to a list of tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4BimrEN1uKYI",
        "outputId": "4527866b-13f7-4818-a3a4-32587faa527b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<llama_index.core.tools.function_tool.FunctionTool at 0x7ace2e63dd00>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x7ace2e63c4d0>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x7ace2e928080>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x7ace2e92e810>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x7ace2e63c110>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x7ace2e63b710>]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from llama_index.tools.google import GmailToolSpec\n",
        "\n",
        "tool_spec = GmailToolSpec()\n",
        "tool_spec_list = tool_spec.to_tool_list()\n",
        "tool_spec_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeZkWy0duKYI"
      },
      "source": [
        "To get a more detailed view of the tools, we can take a look at the `metadata` of each tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5hArVn34uKYJ",
        "outputId": "9e60b212-93e4-4716-d2a7-2a8481ffed2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load_data load_data() -> List[llama_index.core.schema.Document]\n",
            "Load emails from the user's account.\n",
            "search_messages search_messages(query: str, max_results: Optional[int] = None)\n",
            "\n",
            "        Searches email messages given a query string and the maximum number\n",
            "        of results requested by the user\n",
            "           Returns: List of relevant message objects up to the maximum number of results.\n",
            "\n",
            "        Args:\n",
            "            query (str): The user's query\n",
            "            max_results (Optional[int]): The maximum number of search results\n",
            "            to return.\n",
            "\n",
            "        \n",
            "create_draft create_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None) -> str\n",
            "\n",
            "        Create and insert a draft email.\n",
            "           Print the returned draft's message and id.\n",
            "           Returns: Draft object, including draft id and message meta data.\n",
            "\n",
            "        Args:\n",
            "            to (Optional[str]): The email addresses to send the message to\n",
            "            subject (Optional[str]): The subject for the event\n",
            "            message (Optional[str]): The message for the event\n",
            "\n",
            "        \n",
            "update_draft update_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None, draft_id: str = None) -> str\n",
            "\n",
            "        Update a draft email.\n",
            "           Print the returned draft's message and id.\n",
            "           This function is required to be passed a draft_id that is obtained when creating messages\n",
            "           Returns: Draft object, including draft id and message meta data.\n",
            "\n",
            "        Args:\n",
            "            to (Optional[str]): The email addresses to send the message to\n",
            "            subject (Optional[str]): The subject for the event\n",
            "            message (Optional[str]): The message for the event\n",
            "            draft_id (str): the id of the draft to be updated\n",
            "\n",
            "        \n",
            "get_draft get_draft(draft_id: str = None) -> str\n",
            "\n",
            "        Get a draft email.\n",
            "           Print the returned draft's message and id.\n",
            "           Returns: Draft object, including draft id and message meta data.\n",
            "\n",
            "        Args:\n",
            "            draft_id (str): the id of the draft to be updated\n",
            "\n",
            "        \n",
            "send_draft send_draft(draft_id: str = None) -> str\n",
            "\n",
            "        Sends a draft email.\n",
            "           Print the returned draft's message and id.\n",
            "           Returns: Draft object, including draft id and message meta data.\n",
            "\n",
            "        Args:\n",
            "            draft_id (str): the id of the draft to be updated\n",
            "\n",
            "        \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[print(tool.metadata.name, tool.metadata.description) for tool in tool_spec_list]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
