{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da5dc4f",
   "metadata": {},
   "source": [
    "# Notebook Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a790f",
   "metadata": {},
   "source": [
    "## Agent Initialization\n",
    "\n",
    "Since the agent will be used across multiple blocks, we need to initialize it once at the beginning to avoid unintentionally initializing it multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dad139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import ToolAgent  # Ton agent local\n",
    "\n",
    "agent = ToolAgent(model=\"phi3:instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47eb29c",
   "metadata": {},
   "source": [
    "## Questions Data from the GAIA dataset\n",
    "\n",
    "In this section, we import questions from the GAIA dataset and extract information about which tools are used in each question. This allows us to prioritize the implementation of the most relevant tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58c002",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1bb932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('Data/metadata.jsonl', 'r') as jsonl_file:\n",
    "    json_list = list(jsonl_file)\n",
    "\n",
    "json_QA = []\n",
    "for json_str in json_list:\n",
    "    json_data = json.loads(json_str)\n",
    "    json_QA.append(json_data)\n",
    "\n",
    "json_QA_level1 = [item for item in json_QA if str(item.get(\"Level\", \"\")) == \"1\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f347bf8",
   "metadata": {},
   "source": [
    "### Metadatas about one question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# random.seed(42)\n",
    "random_samples = random.sample(json_QA, 1)\n",
    "for sample in random_samples:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Task ID: {sample['task_id']}\")\n",
    "    print(f\"Question: {sample['Question']}\")\n",
    "    print(f\"Level: {sample['Level']}\")\n",
    "    print(f\"Final Answer: {sample['Final answer']}\")\n",
    "    print(f\"Annotator Metadata: \")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Steps: \")\n",
    "    for step in sample['Annotator Metadata']['Steps'].split('\\n'):\n",
    "        print(f\"  ‚îÇ      ‚îú‚îÄ‚îÄ {step}\")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Number of steps: {sample['Annotator Metadata']['Number of steps']}\")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ How long did this take?: {sample['Annotator Metadata']['How long did this take?']}\")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Tools:\")\n",
    "    for tool in sample['Annotator Metadata']['Tools'].split('\\n'):\n",
    "        print(f\"  ‚îÇ      ‚îú‚îÄ‚îÄ {tool}\")\n",
    "    print(f\"  ‚îî‚îÄ‚îÄ Number of tools: {sample['Annotator Metadata']['Number of tools']}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace587e4",
   "metadata": {},
   "source": [
    "### Used tools summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eededaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the tools used in all the samples\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "tools = []\n",
    "for sample in json_QA:\n",
    "    for tool in sample['Annotator Metadata']['Tools'].split('\\n'):\n",
    "        tool = tool[2:].strip().lower()\n",
    "        if tool.startswith(\"(\"):\n",
    "            tool = tool[11:].strip()\n",
    "        tools.append(tool)\n",
    "tools_counter = OrderedDict(Counter(tools))\n",
    "print(\"List of tools used in all samples:\")\n",
    "print(\"Total number of tools used:\", len(tools_counter))\n",
    "for tool, count in tools_counter.items():\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ {tool}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f621e",
   "metadata": {},
   "source": [
    "## Verification of Proper Tool Usage\n",
    "\n",
    "Before testing on the dataset, we first ensure that the agent and its tools function correctly by using simple questions, before moving on to more complex ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d57118",
   "metadata": {},
   "source": [
    "### Tool verification\n",
    "\n",
    "The following block is intended for directly testing the tools. This ensures that when the Agent invokes a tool, it performs as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tools import ToolExecutor\n",
    "\n",
    "# Liste de tests √† ex√©cuter\n",
    "test_cases = [\n",
    "    (\"add\", [\"3\", \"5\"]),\n",
    "    (\"multiply\", [\"7\", \"6\"]),\n",
    "    (\"subtract\", [\"10\", \"4\"]),\n",
    "    (\"divide\", [\"20\", \"5\"]),\n",
    "    (\"modulus\", [\"13\", \"5\"]),\n",
    "    (\"wiki_search\", [\"Albert Einstein\"]),\n",
    "    (\"web_search\", [\"current president of France\"]),\n",
    "]\n",
    "\n",
    "# Stocke les r√©sultats\n",
    "results = []\n",
    "\n",
    "for tool_name, args in test_cases:\n",
    "    args_str = ', '.join(f'\"{arg}\"' for arg in args)\n",
    "    command = f'Action: {tool_name}[{args_str}]'\n",
    "    print(f\"\\nüõ†Ô∏è Testing tool: {tool_name}\")\n",
    "    print(f\"‚û°Ô∏è Command: {command}\")\n",
    "    result = ToolExecutor.execute(command)\n",
    "    print(f\"üì§ Result: {result}\")\n",
    "    results.append({\n",
    "        \"tool\": tool_name,\n",
    "        \"command\": command,\n",
    "        \"result\": result,\n",
    "        \"success\": \"Observation:\" in result and \"error\" not in result.lower()\n",
    "    })\n",
    "\n",
    "# R√©sum√© final\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\nüìä TEST SUMMARY:\")\n",
    "print(df[[\"tool\", \"success\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0202b019",
   "metadata": {},
   "source": [
    "### Call verification\n",
    "\n",
    "This section is used to test whether the agent correctly selects and uses the appropriate tool when given simple, direct questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    {\"id\": \"q_add\", \"question\": \"What is 12 plus 30?\",\"expected\": \"42\"},\n",
    "    {\"id\": \"q_subtract\", \"question\": \"What is 100 minus 33?\",\"expected\": \"67\"},\n",
    "    {\"id\": \"q_multiply\", \"question\": \"What is 8 multiplied by 7?\",\"expected\": \"56\"},\n",
    "    {\"id\": \"q_divide\", \"question\": \"What is 81 divided by 9?\",\"expected\": \"9\"},\n",
    "    {\"id\": \"q_wiki\", \"question\": \"Who developed the theory of evolution?\",\"expected\": \"Charles Darwin\"},\n",
    "    {\"id\": \"q_web\", \"question\": \"Who is the current president of the United States?\",\"expected\": \"Donald Trump\"},\n",
    "    {\"id\": \"q_extract\", \"question\": \"Who founded Wikipedia?\",\"expected\":\"Jimmy Wales, Larry Sanger\"},\n",
    "    {\"id\": \"q_chain\", \"question\": \"What is the sum of 5 and 6, multiplied by 3?\",\"expected\":\"33\"}\n",
    "]\n",
    "\n",
    "for test in test_questions:\n",
    "    print(f\"üü® --- Testing {test['id']} ---\")\n",
    "    question_unique = test[\"question\"]\n",
    "\n",
    "    # Mode avec trace\n",
    "    logged = agent(question_unique, log=True)\n",
    "    print(\"\\nüìú Full trace with log:\")\n",
    "    print(\"‚úÖ Final answer:\", logged['final_answer'],\"   |   Expected:\", test[\"expected\"])\n",
    "    print(\"üõ†Ô∏è Tools used:\", logged['used_tools'])\n",
    "    # print(\"üìú Trace:\\n\", logged['trace'])\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a5e62f",
   "metadata": {},
   "source": [
    "## Evaluation on GAIA data\n",
    "\n",
    "In this section, we select random level 1 questions from the GAIA dataset and test our agent to evaluate its ability to answer them correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5add2a",
   "metadata": {},
   "source": [
    "### Running the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from agent import ToolAgent  # Ton agent local\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(1)\n",
    "evaluation_samples = random.sample(json_QA_level1, 15)  # Ajuste la taille si besoin\n",
    "\n",
    "# If not you need to initialize your agent \n",
    "\n",
    "# R√©sultats stock√©s ici\n",
    "results = []\n",
    "\n",
    "for sample in evaluation_samples:\n",
    "    task_id = sample[\"task_id\"]\n",
    "    question = sample[\"Question\"]\n",
    "    expected = sample[\"Final answer\"].strip().lower()\n",
    "\n",
    "    try:\n",
    "        # Appel de l'agent en mode log\n",
    "        print(f\"\\nüü® --- TRACE FOR TASK {task_id} ---\")\n",
    "        print(f\"üß† Question: {question}\")\n",
    "        response = agent(question, log=True)  # ‚úÖ utilisation du log\n",
    "\n",
    "        answer = response[\"final_answer\"].strip().lower()\n",
    "        tools_used = response[\"used_tools\"]\n",
    "        trace = response[\"trace\"]\n",
    "\n",
    "        print(f\"‚úÖ Agent Answer: {answer}\")\n",
    "        print(f\"üõ†Ô∏è Tools used: {tools_used}\")\n",
    "        # print(f\"üìú Trace:\\n{trace}\") # Uncomment this if you want more details about the reasonning process\n",
    "\n",
    "    except Exception as e:\n",
    "        answer = f\"ERROR: {e}\"\n",
    "        tools_used = []\n",
    "        trace = f\"ERROR TRACE: {e}\"\n",
    "        print(f\"‚ùå ERROR during agent call: {e}\")\n",
    "\n",
    "    results.append({\n",
    "        \"task_id\": task_id,\n",
    "        \"question\": question,\n",
    "        \"expected\": expected,\n",
    "        \"answer\": answer,\n",
    "        \"tools_used\": tools_used,\n",
    "        \"correct\": answer == expected,\n",
    "        \"trace\": trace\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282f1d1",
   "metadata": {},
   "source": [
    "### Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Exemple de structure `results` (√† remplacer par ta variable r√©elle si diff√©rente)\n",
    "# results = [...]  # Doit d√©j√† √™tre d√©fini depuis la boucle d'√©valuation\n",
    "\n",
    "# Cr√©ation du DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results[\"correct\"] = df_results[\"correct\"].astype(bool)\n",
    "df_results[\"used_tool\"] = df_results[\"tools_used\"].apply(lambda tools: bool(tools and len(tools) > 0))\n",
    "\n",
    "# R√©sum√© global\n",
    "accuracy = df_results[\"correct\"].mean() * 100\n",
    "tool_usage = df_results[\"used_tool\"].mean() * 100\n",
    "average_tool_count = df_results[\"tools_used\"].apply(lambda tools: len(tools) if tools else 0).mean()\n",
    "\n",
    "# Affichage console\n",
    "print(f\"\\n‚úÖ Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"üõ†Ô∏è Tool usage rate: {tool_usage:.2f}%\")\n",
    "print(f\"üõ†Ô∏è Average tools count: {average_tool_count:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de884e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>used_tool</th>\n",
       "      <th>nb_tools</th>\n",
       "      <th>tools_used</th>\n",
       "      <th>answer</th>\n",
       "      <th>expected</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2d83110e-a098-4ebb-9987-066c06fa42d0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>['extract_answer', 'wiki_search']</td>\n",
       "      <td>list including rewsnee elementary school.</td>\n",
       "      <td>right</td>\n",
       "      <td>.rewsna eht sa \"tfel\" drow eht fo etisoppo eht etirw ,ecnetnes siht dnatsrednu uoy fI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e142056d-56ab-4352-b091-b56054bd1359</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['multiply']</td>\n",
       "      <td>6800</td>\n",
       "      <td>16000</td>\n",
       "      <td>Bob was invited to participate in a game show, and he advanced to the final round. The final round offered Bob the chance to win a large sum by playing a game against the host. The host has 30 shiny prop coins, each of which is worth $1,000 if Bob manages to win them by playing the game. The host hides the coins in three different prize boxes and then shuffles their order. The only rule restricting the host's coin placement is that one box must contain at least 2 coins, and one box must contain 6 more coins than another box. In order to play, Bob must submit three guesses, one guess for the number of coins in each box. The box is then opened and the number of coins is revealed. If Bob's guess is a number greater than the number of coins in the box, Bob earns no coins. If Bob guesses a number equal to or less than the number of coins in the box, Bob wins a number of coins equal to his guess.\\n\\nIf Bob plays uses the optimal strategy, what's the minimum amount of money he can win from the game?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50ec8903-b81f-4257-9450-1085afd2c319</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>['wiki_search', 'wiki_search']</td>\n",
       "      <td>blue, orange</td>\n",
       "      <td>green, white</td>\n",
       "      <td>A standard Rubik‚Äôs cube has been broken into cubes making up its sides. The cubes are jumbled, and one is removed. There are 6 cubes with one colored face, 12 edge cubes with two colored faces, and 8 corner cubes with three colored faces. All blue cubes have been found. All cubes directly left, right, above, and below the orange center cube have been found, along with the center cube. The green corners have all been found, along with all green that borders yellow. For all orange cubes found, the opposite face‚Äôs cubes have been found. The removed cube has two colors on its faces. What are they? Answer using a comma separated list, with the colors ordered alphabetically.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1e91b78-d3d8-4675-bb8d-62741b4b68a6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['web_search']</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>In the video https://www.youtube.com/watch?v=L1vXCYZAYYM, what is the highest number of bird species to be on camera simultaneously?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cca530fc-4052-43b2-b130-b30968d8aa44</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['wiki_search']</td>\n",
       "      <td>ra8+</td>\n",
       "      <td>rd5</td>\n",
       "      <td>Review the chess position provided in the image. It is black's turn. Provide the correct next move for black which guarantees a win. Please provide your response in algebraic notation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cffe0e32-c9a6-4c52-9877-78ceb4aaa9fb</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>['extract_answer', 'wiki_search']</td>\n",
       "      <td>not identifiable from the available data; further investigation needed using web search or extracting additional context if possible. if unable to identify, it might be john doe assuming he is mentioned in a related document but unspecified herein.</td>\n",
       "      <td>fred</td>\n",
       "      <td>An office held a Secret Santa gift exchange where each of its twelve employees was assigned one other employee in the group to present with a gift. Each employee filled out a profile including three likes or hobbies. On the day of the gift exchange, only eleven gifts were given, each one specific to one of the recipient's interests. Based on the information in the document, who did not give a gift?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d0633230-7067-47a9-9dbf-ee11e0a2cdd6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['wiki_search']</td>\n",
       "      <td>knn, logisticregressionbaseclassifier</td>\n",
       "      <td>baselabelpropagation</td>\n",
       "      <td>In the Scikit-Learn July 2017 changelog, what other predictor base command received a bug fix? Just give the name, not a path.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cabe07ed-9eca-40ea-8ead-410ef5e83f91</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['wiki_search']</td>\n",
       "      <td>dr. linda peters</td>\n",
       "      <td>louvrier</td>\n",
       "      <td>What is the surname of the equine veterinarian mentioned in 1.E Exercises from the chemistry materials licensed by Marisa Alviar-Agnew &amp; Henry Agnew under the CK-12 license in LibreText's Introductory Chemistry materials as compiled 08/21/2023?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99c9cc74-fdc8-46c6-8f8d-3ce2d3bfeea3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['web_search']</td>\n",
       "      <td>fresh strawberries, lemons (zest), sugar</td>\n",
       "      <td>cornstarch, freshly squeezed lemon juice, granulated sugar, pure vanilla extract, ripe strawberries</td>\n",
       "      <td>Hi, I'm making a pie but I could use some help with my shopping list. I have everything I need for the crust, but I'm not sure about the filling. I got the recipe from my friend Aditi, but she left it as a voice memo and the speaker on my phone is buzzing so I can't quite make out what she's saying. Could you please listen to the recipe and list all of the ingredients that my friend described? I only want the ingredients for the filling, as I have everything I need to make my favorite pie crust. I've attached the recipe as Strawberry pie.mp3.\\n\\nIn your response, please only list the ingredients, not any measurements. So if the recipe calls for \"a pinch of salt\" or \"two cups of ripe strawberries\" the ingredients on the list would be \"salt\" and \"ripe strawberries\".\\n\\nPlease format your response as a comma separated list of ingredients. Also, please alphabetize the ingredients.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dc22a632-937f-4e6a-b72f-ba0ff3f5ff97</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['web_search']</td>\n",
       "      <td>the complete title is not explicitly mentioned, but it relates to recommendations by james beard award winners within the context of chris schlesinger and alvin yapa's book \"the food lover's guide to las vegas\" regarding new mexican food.</td>\n",
       "      <td>five hundred things to eat before it's too late: and the very best places to eat them</td>\n",
       "      <td>What was the complete title of the book in which two James Beard Award winners recommended the restaurant where Ali Khan enjoyed a New Mexican staple in his cost-conscious TV show that started in 2015? Write the numbers in plain text if there are some in the title.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a3fbeb63-0e8c-4a11-bff6-0e3b484c3e9c</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['web_search']</td>\n",
       "      <td>1,2-4</td>\n",
       "      <td>4</td>\n",
       "      <td>How many slides in this PowerPoint presentation mention crustaceans?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>72e110e7-464c-453c-a309-90a95aed6538</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['wiki_search']</td>\n",
       "      <td>not specified as of 2020; the country with a presence at bielefeld university's library isn't determined by language origin alone on ddc 633 section about unknown languages</td>\n",
       "      <td>guatemala</td>\n",
       "      <td>Under DDC 633 on Bielefeld University Library's BASE, as of 2020, from what country was the unknown language article with a flag unique from the others?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4b6bb5f7-f634-410e-815d-e673ab7f8632</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['wiki_search']</td>\n",
       "      <td>on the planet kodiet</td>\n",
       "      <td>the castle</td>\n",
       "      <td>In Series 9, Episode 11 of Doctor Who, the Doctor is trapped inside an ever-shifting maze. What is this location called in the official script for the episode? Give the setting exactly as it appears in the first scene heading.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a0068077-79f4-461a-adfe-75c1a4148545</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['wiki_search']</td>\n",
       "      <td>45</td>\n",
       "      <td>90</td>\n",
       "      <td>What was the actual enrollment count of the clinical trial on H. pylori in acne vulgaris patients from Jan-May 2018 as listed on the NIH website?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8e867cd7-cff9-4e6c-867a-ff5ddc2550be</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>['wiki_search']</td>\n",
       "      <td>five</td>\n",
       "      <td>3</td>\n",
       "      <td>How many studio albums were published by Mercedes Sosa between 2000 and 2009 (included)? You can use the latest 2022 version of english wikipedia.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cr√©ation du DataFrame complet depuis la liste results\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Ajout √©ventuel de colonnes d'analyse (facultatif mais utile)\n",
    "df_results[\"used_tool\"] = df_results[\"tools_used\"].apply(lambda tools: bool(tools and len(tools) > 0))\n",
    "df_results[\"nb_tools\"] = df_results[\"tools_used\"].apply(lambda tools: len(tools) if tools else 0)\n",
    "\n",
    "# Colonnes √† afficher (tout le contenu pertinent)\n",
    "columns_to_display = [\n",
    "    \"task_id\",\n",
    "    \"question\",\n",
    "    \"expected\",\n",
    "    \"answer\",\n",
    "    \"tools_used\",\n",
    "    \"correct\",\n",
    "    \"used_tool\",\n",
    "    \"nb_tools\",\n",
    "    \"trace\"\n",
    "]\n",
    "columns_synthetiques = [\"task_id\", \"correct\", \"used_tool\", \"nb_tools\", \"tools_used\",\"answer\",\"expected\",\"question\"]\n",
    "\n",
    "# Affichage du tableau complet\n",
    "full_summary_df = df_results[columns_to_display]\n",
    "summary_df = df_results[columns_synthetiques]\n",
    "\n",
    "full_summary_df.to_csv(\"Results/resultats_complets.csv\", index=False)\n",
    "summary_df.to_csv(\"Results/resultats.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"Results/resultats.csv\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(df.to_html(max_rows=100, max_cols=20))\n",
    "\n",
    "# For just one line\n",
    "# print(df_results[df_results[\"task_id\"] == 3].iloc[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
